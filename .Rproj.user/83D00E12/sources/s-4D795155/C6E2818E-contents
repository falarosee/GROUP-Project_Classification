---
title: "GroupE_Classification"
date: "5/29/2019"
output:
  html_document:
    toc: true
    toc_depth: 3
author: "Group E"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, COMMENT = NA, warning = FALSE)
start_time <- Sys.time()
print(paste0('---START--- Starting at ',start_time))
packages_list <- c(
  'caret',
  'corrplot',
  'data.table',
  'DMwR',
  'dplyr',
  'GGally',
  'ggplot2',
  'lubridate',
  'MLmetrics')
for (i in packages_list){
  if(!i%in%installed.packages()){
    install.packages(i, dependencies = TRUE)
    library(i, character.only = TRUE)
    print(paste0(i, ' has been installed'))
  } else {
    print(paste0(i, ' is already installed'))
    library(i, character.only = TRUE)
  }
}
print(paste0('[', round(difftime(Sys.time(),start_time, units = 'secs'),1), 's]: ',
             'All necessary packages installed and loaded'))
```

## 1. Introduction

The dataset provided gathers information related to a telemarketing campaign applied by a banking institution. Throughout the campaign, clients were contacted multiple times in regard to a term deposit subscription offer. 

The goal of this project is to predict if a client will subscribe to the term deposit offer. To this end a classification analysis was conducted. The term deposit target variable is labelled 'y', and has the possible outcomes 'yes' or 'no'. 

## 2. Data Loading and Preprocessing

The first part of this report revolves around understanding the data. Here, the data quality is evaluated and some basic cleaning and pre-processing is undertaken in order to prepare the data for the baseline model which will act as a benchmark for all future data transformation in the feature engineering process. Within this pipe-line, pre-processing involves anything that can be done to get the data ready for a baseline model that does not require an EDA (Exploratory Data Analysis). This typically involves loading the data, merging it, looking for NA's, looking for missing values, dropping meaningless variables and correcting variable types. 

First, we load the necessary train and test data.

```{r load}
train = fread("BankCamp_train.csv", stringsAsFactors = T)
test = fread("BankCamp_test.csv", stringsAsFactors = T)
```

Here we switch the order of the factors, to get metrics related to the yes target.

```{r change_factors}
train$y <- factor(train$y, levels = c("yes", "no"))
test$y <- factor(test$y, levels = c("yes", "no"))
```

We explore the first few rows, structure and summary of the training data to see if there are any inconsistencies.

```{r head}
head(train)
```

This is the structure of the data.

```{r str}
str(train)
```

This is the summary of the data.

```{r summary}
summary(train)
```
We see that the data seems quite clean, apart from some varible types that we might want to change later. 

Now we check if there are missing values in any column:

```{r missing}
sapply(train, function(x) sum(is.na(x)))
```

We also check if there are any duplicate values:

```{r duplicated}
any(duplicated(train))
```
We see there are neither inconsistent missing values nor duplicates in the set. However, we see that the "pdays" variable contains '-1' values, which we assume indicates that the information is not applicable to the client.

Finally we set the types for numerical variables:

```{r numerical}
train[ , which(sapply(train, is.integer)):=lapply(.SD,as.numeric), .SDcols = sapply(train, is.integer)]
test[ , which(sapply(test, is.integer)):=lapply(.SD,as.numeric), .SDcols = sapply(test, is.integer)]
str(train)
```

## 3. Exploratory Data Analysis (EDA)

In the first step, we explore the distributions of the variables, in order to gain insights into the data and inform decisions on the later feature engineering and modelling process.

### 3.1 Target Variable Distribution

```{r}
sort(summary(train$y), dec=T)/nrow(train)

p1<-ggplot(train, aes(x=y))+geom_bar(stat='count',fill="dodgerblue4", colour="dodgerblue4", label = TRUE)+
  theme(axis.text.x = element_text(angle=0))+ labs(title = "Distribution of Clients Subscribed")+
  xlab("y")+ ylab("Count")
train[, job:=factor(job, levels=names(sort(summary(train$job), dec=T)))]
levels(train$job)
p1
```
<hr />

We see that the target variable is heavily unballanced, with over 85% of the values denoting 'no'. In the business context this is explained by the fact that the term deposit subscription is not targeted towards the majority of clients. 

For later modelling and model evaluation, this poses a challenge, as the model is likely to achieve a high accuracy by purely training on and predicting 'no' targets, despite having a very low sensitivity score (namely being poor at correctly indentifying true positive targets). 

### 3.2 Numerical Variable Distributions

#### 3.21 Numeric Correlation Plot

Next, a correlation plot is constructed to see if there is any significant correlation between explanatory variables.

```{r}
numerical <- select_if(train,is.numeric)
corr_plot <- ggcorr(numerical,  label_round=2, label = TRUE)
corr_plot
```

As we can see, no variables have significant correlations, apart from "previous" and "pdays". We therefore do not need to spend a lot of time on transforming or dropping variables purely based on multivariate correlation between numeric explanatory variables. 

#### 3.22 Numeric Distributions Plot

```{r}
num_y <- train[, c('age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous','y')]
ggpairs(num_y[,1:8], title = "Distribution & Correlation graph", ggplot2::aes(colour=y, alpha=1/100))
```
In the above graph we see how the numeric variables relate to each other and to the target variable. We can see through the diagram diagonal, that their might be trends within the continuous distributions of the explanatory variables that match up more with certain yes, or certain no factors and can explore using these trends to bin variables in the feature engineering phase.
<hr />


### 3.23 Skewness, Numerical Variables

Next we check univariate distributions of each categorical variable, to see if the numerical variables are skewed, or if some factors of the categorical variables account for more of the data, than others.

```{r}
numDist<- c('age', 'balance', 'day', 'duration', 'campaign', 'pdays', 'previous')
for(i in numDist){
  counts <- table(train[,..i])
  barplot(counts, main = i, col = 'dodgerblue4')
}
```
We see that many of the variables are skewed, so we will consider normalizing the scales of the numeric variables at a later stage. 
<hr />

### 3.3 Catagorical Variable Distribution
In this subsection, we explore the categorical variable distributions, to inform on later feature engineering decisions.

#### 3.31 Job univariate bar chart (count)
```{r}
sort(summary(train$job), dec=T)/nrow(train)

p1<-ggplot(train, aes(x=job))+geom_bar(stat='count',fill="dodgerblue4", colour="dodgerblue4")+
  theme(axis.text.x = element_text(angle=90))+ labs(title = "Distribution by Kind of Job")+
  xlab("Job")+ ylab("Count")
train[, job:=factor(job, levels=names(sort(summary(train$job), dec=T)))]
levels(train$job)
p1
```
We see that a large portion of potential targets is made up of blue collar and management related jobs.
<hr />


#### 3.32 Marital univariate bar chart (count)
```{r}
sort(summary(train$marital), dec=T)/nrow(train)

p2<-ggplot(train, aes(x=marital))+geom_bar(stat='count',fill="dodgerblue4", colour="dodgerblue4")+
  theme(axis.text.x = element_text(angle=0))+ labs(title = "Distribution by Marital Status")+
  xlab("Marital Status")+ ylab("Count")
train[, marital:=factor(marital, levels=names(sort(summary(train$marital), dec=T)))]
levels(train$marital)
p2
```
Most of the historic potential targets were married, with a fraction being divorced.
<hr />


#### 3.33 Education univariate bar chart (count)
```{r}
sort(summary(train$education), dec=T)/nrow(train)

p3<-ggplot(train, aes(x=education))+geom_bar(stat='count',fill="dodgerblue4", colour="dodgerblue4")+
  theme(axis.text.x = element_text(angle=0))+labs(title = "Distribution by Education Level")+
  xlab("Education Level")+ ylab("Count")
train[, education:=factor(education, levels=names(sort(summary(train$education), dec=T)))]
levels(train$education)
p3
```
Most historic potential targets have at least secondary education, making them good candidates from a business point of view.
<hr />

#### 3.34 Month univariate bar chart (count)
```{r}
sort(summary(train$month), dec=T)/nrow(train)
train$month <- factor(train$month, levels = c( "jan", "feb", "mar", "apr","may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"))
p4<-ggplot(train, aes(x=month))+geom_bar(stat='count',fill="dodgerblue4", colour="dodgerblue4")+
  theme(axis.text.x = element_text(angle=90))+labs(title = "Distribution by Month")+
  xlab("Month")+ ylab("Count")
levels(train$month)
p4
```

We see spikes of subscriptions in May, sustained throughout the summer and dropping during the rest of the year.
<hr />


#### 3.35 Loan univariate bar chart (count)
```{r}
sort(summary(train$loan), dec=T)/nrow(train)

p23<-ggplot(train, aes(x=loan))+geom_bar(stat='count',fill="dodgerblue4", colour="dodgerblue4")+
  theme(axis.text.x = element_text(angle=0))+labs(title = "Loans Acquired")+
  xlab("Loans")+ ylab("Count")
p23
```
We see that the majority of potential targets do not have a loan.
<hr />

#### 3.36 Housing Loan univariate bar chart (count)
```{r}
sort(summary(train$housing), dec=T)/nrow(train)

p24<-ggplot(train, aes(x=housing))+geom_bar(stat='count',fill="dodgerblue4", colour="dodgerblue4")+
  theme(axis.text.x = element_text(angle=0))+labs(title = "Housing Loan Acquired")+
  xlab("Housing Loan")+ ylab("Count")
p24
```
The housing loans however, are more ballenced.
<hr />

#### 3.37 Contact univariate bar chart (count)
```{r}
sort(summary(train$contact), dec=T)/nrow(train)

p24<-ggplot(train, aes(x=contact))+geom_bar(stat='count',fill="dodgerblue4", colour="dodgerblue4")+
  theme(axis.text.x = element_text(angle=0))+labs(title = "Contact Type")+
  xlab("Contact")+ ylab("Count")
p24
```
Most potential applicants can be reached by cellular phone, a significant portion however cannot be reached, as they are unknown. 
<hr />

#### 3.38 Previous Campaign  univariate bar chart (count)
```{r}
sort(summary(train$poutcome), dec=T)/nrow(train)

p24<-ggplot(train, aes(x=poutcome))+geom_bar(stat='count',fill="dodgerblue4", colour="dodgerblue4")+
  theme(axis.text.x = element_text(angle=0))+labs(title = "Previous Campaign Outcome")+
  xlab("Outcome")+ ylab("Count")
p24
```
<hr />
Here we have so many unknown values, that this variable does not seem to add a lot to the evaluation.

### 3.4 Bivariate Analysis
In the bivariate analysis, we see what proportion of clients have subscribed and not subscribed according to each variable. We further explore trends amongst the explanatory variables, to inform further feature creation.

#### 3.41 Marital 
```{r}
#Marital + Loan bar chart (count)
p6<-ggplot(train, 
           aes(x = marital, 
               fill = loan)) + 
  geom_bar(position = "dodge")+ scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
  labs(title = "Loan Acquisition by Marital Status")+xlab("Marital Status")+ ylab("Count")
p6
```
We see that the proportion of loans seems to fit to the proportion of factors within the variable, suggesting that it has less explanatory value.

#### 3.42 Marital + Default bar chart (count)
```{r}
p7<-ggplot(train, 
             aes(x = marital, 
                 fill = default)) + 
    geom_bar(position = "dodge")+ scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
  labs(title = "Default by Marital Status")+xlab("Marital Status")+ ylab("Count")
p7
```

#### 3.43 Marital + y bar chart (percent)
```{r}
mytable <- table(train$marital, train$y)
tab <- as.data.frame(prop.table(mytable, 2))
colnames(tab) <-  c("marital", "y", "perc")

p8<-ggplot(data = tab, aes(x = marital, y = perc, fill = y)) + 
  geom_bar(stat = 'identity', position = 'dodge', alpha = 1) + scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
  labs(title = "Term Deposit Subscription by Marital Status")+xlab("Marital Status")+ ylab("Percent")
p8
```
We see that a greater prorportion of single clients seem to go for a loan subscription than maried or divorced couples.

#### 3.44 Education + Loan bar chart (count)
```{r}
p9<-ggplot(train, 
           aes(x = education, 
               fill = loan)) + 
  geom_bar(position = "dodge")+ scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
  labs(title = "Loan Acquisition by Education Level")+xlab("Education Level")+ ylab("Count")
p9
```

#### 3.45 Education + Default bar chart (count)
```{r}
p10<-ggplot(train, 
           aes(x = education, 
               fill = default)) + 
  geom_bar(position = "dodge")+ scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
  labs(title = "Default by Education Level")+xlab("Education Level")+ ylab("Count")
p10
```

#### 3.46 Education + y bar chart (percent)
```{r}
mytable <- table(train$education, train$y)
tab <- as.data.frame(prop.table(mytable, 2))
colnames(tab) <-  c("education", "y", "perc")

p11<- ggplot(data = tab, aes(x = education, y = perc, fill = y)) + 
  geom_bar(stat = 'identity', position = 'dodge', alpha = 1) + scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
labs(title = "Term Deposit Subscription by Education Level")+xlab("Education Level")+ ylab("Percent")
p11
```
Secondary education seems to have some explanatory value, in predicting the target.


#### 3.47 Job + Loan bar chart (count)
```{r}
p12<-ggplot(train, 
           aes(x = job, 
               fill = loan)) + 
  geom_bar(position = "dodge")+ scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+theme(axis.text.x = element_text(angle=90))+
  labs(title = "Job by Loan Status")+xlab("Job")+ ylab("Count")
p12
```

#### 3.48 Job + Default bar chart (count)
```{r}
p13<-ggplot(train, 
            aes(x = job, 
                fill = default)) + 
  geom_bar(position = "dodge")+ scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+theme(axis.text.x = element_text(angle=90))+
  labs(title = "Default Status by Job")+xlab("Job")+ ylab("Count")
p13
```

#### 3.48 Job + y bar chart (percent)
```{r}
mytable <- table(train$job, train$y)
tab <- as.data.frame(prop.table(mytable, 2))
colnames(tab) <-  c("job", "y", "perc")

p14<-ggplot(data = tab, aes(x = job, y = perc, fill = y)) + 
  geom_bar(stat = 'identity', position = 'dodge', alpha = 1) + scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "Term Deposit Subscription by Job")+xlab("Job")+ ylab("Percent")
p14
```
It seems that clients that are retired or holding management jobs have the greatest incentive of subscribing to a term deposit. 

#### 3.49 Balance + education box plot
```{r}
p15<-ggplot(train, 
       aes(x = education, 
           y = balance)) + geom_line(size = 1.5, 
                                     color = "lightgrey") +
  geom_boxplot(fill="dodgerblue3", color="dodgerblue4") +
  labs(title = "Balance by Education Level")+xlab("Education")+ ylab("Balance")
p15
```

### 3.410 Balance + education scatter plot
```{r}
p16<-ggplot(train, 
            aes(y = balance, 
                x = education)) +  
  geom_jitter(color = "dodgerblue4") + 
  labs(title = "Balance Distribution by Education Level")+theme(axis.text.x = element_text(angle=90))+
  xlab("Education")+ ylab("Balance")
p16
```

#### 3.411 Balance + job box plot
```{r}
p17<-ggplot(train, 
            aes(x = job, 
                y = balance)) + geom_line(size = 1.5, 
                                          color = "lightgrey") +
  geom_boxplot(fill="dodgerblue3", color="dodgerblue4") +
  labs(title = "Balance by Kind of Job")+theme(axis.text.x = element_text(angle=90))+
  xlab("Job")+ ylab("Balance")
p17
```

#### 3.412 Balance + job scatter plot
```{r}
p18<-ggplot(train, 
       aes(y = balance, 
           x = job)) +  
  geom_jitter(color = "dodgerblue4") + 
  labs(title = "Balance Distribution by Kind of Job")+theme(axis.text.x = element_text(angle=90))+
  xlab("Job")+ ylab("Balance")
p18
```

#### 3.413 Duration + y
```{r}
p19<-ggplot(train, aes(x=as.factor(y), y=duration)) +
  geom_boxplot(fill="dodgerblue3", color="dodgerblue4")+
  theme_classic()+labs(title = "Call Duration by Term Deposit Subscription")+xlab("Term deposit")+
  ylab("Call Duration (sec.)")
p19
```

#### 3.415 Pdays + y
```{r}
p20<-ggplot(train, aes(x=as.factor(y), y=pdays)) +
  geom_boxplot(fill="dodgerblue3", color="dodgerblue4")+
  theme_classic()+labs(title = "Days from last contact by Term Deposit Subscription")+xlab("Term deposit")+
  ylab("Days from last contact")
p20
```

#### 3.416 Previous + y
```{r}
p21<-ggplot(train, aes(x=as.factor(y), y=previous)) +
  geom_boxplot(fill="dodgerblue3", color="dodgerblue4")+
  theme_classic()+labs(title = "Contacts before this Campaign by Term Deposit Subscription")+xlab("Term deposit")+
  ylab("Contacts before this campaign")
p21
```

#### 3.417 Campaign + y
```{r}
p22<-ggplot(train, aes(x=as.factor(y), y=campaign)) +
  geom_boxplot(fill="dodgerblue3", color="dodgerblue4")+
  theme_classic()+labs(title = "Contacts during this Campaign by Term Deposit Subscription")+xlab("Term deposit")+
  ylab("Contacts during this campaign")
p22
```

### 3.418 Coefficient of Variation
The coefficient of variation is a dimensionless meassure of dispersion in data, the lower the value the less dispersion a feature has.

```{r}
numeric_variables<-names(numerical)
sd_numeric_variables<-sapply(train[,numeric_variables, with=F], sd)
cv_numeric_variables<-sd_numeric_variables/colMeans(train[,numeric_variables, with=F])

ggplot(data.table(var=names(cv_numeric_variables),cv=cv_numeric_variables),
       aes(var,fill=cv))+geom_bar()+coord_polar()+scale_fill_gradient(low='white', high = 'dodgerblue4')

```
Viewing variables with less than a 0.05 coefficient of variation. There are none.

```{r}
cv_numeric_variables[cv_numeric_variables < 0.05]
```

### 3.5 Linear Dependencies
Caret uses QR decomposition to enumerate sets of linear combinations and therefore, remove them, however there are none.

```{r}
lc<-findLinearCombos(train[, ..numeric_variables])
lc
```

## 4. Baseline

### 4.1 Setting up Preprocessing: Centering, Scaling and performing a Yeo Johnson transformation
To reduce the weight/importance of certain features due to their scale, we center them and scale them. We also reduce skewness by performing a Yeo Johnson transformation. This combination will be performed on each model training.
```{r}
pp<-c("center", "scale", "YeoJohnson")
preProcess(train, method =pp)
```

### 4.2 Dummy Encoding
We dummy encode the factor variables to be able to run different models on the data.

```{r dummy}
dummy<-dummyVars(formula= ~., data = train[, -"y"], sep = "_")
final_train<-data.table(predict(dummy, newdata = train[, -"y"]))
final_train$y<-train$y
final_test<-data.table(predict(dummy, newdata = test))
head(final_train)
```

Now we define our training function, it will perform a 5 fold cross validation on 80% of the training data and then a final validation on the remaining 20% of the data that acts as a holdout. It also does the aforementioned preprocessing.

```{r}
train_val<- function(train_dt, model, sampling){
  tc<-trainControl(
    method = "cv",
    number=5,
    savePredictions = TRUE,
    classProbs=TRUE,
    summaryFunction = prSummary)

  trainIndex <- createDataPartition(train_dt$y, p = .8, list = FALSE)
  model_train <- train_dt[ trainIndex,]
  holdout  <- train_dt[-trainIndex,]
  
  if(!missing(sampling)){
    if(sampling == 'over'){
      model_train<-upSample(x = model_train[, -"y"],y = model_train$y, yname="y")
    }
    else if(sampling == 'under'){
      model_train<-downSample(x = model_train[, -"y"],y = model_train$y, yname="y")
    }
    else {
      model_train<-SMOTE(y ~ ., data  = model_train) 
    }
  }
  
  ini<-now()
  model<- train(y~ ., data = model_train, method = model, metric="AUC", trControl=tc, preProcess=pp)
  message("Cross Validation Scores having Yes as the positive class")
  message(model$results)
  message("Train + Predict time:")
  message(now()-ini)
  
  predicted = predict(model, newdata = holdout)
  
  message("Holdout Scores")
  message(confusionMatrix(table(predicted, holdout$y), positive="yes", mode="everything"))
  
  return(model)
}
```

Now we will run a simple logistic regression as a baseline, this will serve as a way of knowing if our feature engineering steps improve performance.

```{r baseline}
lm <- train_val(final_train, "glm")
```

So our Sensitivity or Recall is very low based on the "yes" class, meaning that we correctly classify a really small set of the "yes" cases.

Now we run a random forest as an alternative baseline.

```{r}
rf <- train_val(final_train, "ranger")
```

## 5. Feature Engineering
Here we merge the two datasets to perform multiple feature engineering steps
```{r feature engineering}
y <- final_train$y
final_train$y <- NULL
merged_df <- rbind(final_train, final_test)
```

### 5.1 Days to end of month assuming all the months have 30 days
We create a variable that measures days to end of month, to see if the date contacted could have any explanatory value in our prediction.
```{r}
merged_df$days_to_end_of_month <- 30 - merged_df$day
```

### 5.2 Balance General Status -> 1 if positive, 0 if negative or 0
We booleanize the 'balance' variable, to make the distinction between having a balance and not, more explicit.
```{r}
positive_balance <- function(number){
  is_positive = 0
  if(number>0){is_positive <- 1}
  return(is_positive)
}
merged_df$balance_general_status <- as.numeric(lapply(merged_df$balance,  FUN = positive_balance))
```

### 5.3 Quantity of loans 0, 1 or 2 (housing and personal)
We create a quantity of loans category, since having a loan or more can make a difference in the decision of a potential client.
```{r}
merged_df$quantity_loans <- merged_df$housing_yes+merged_df$loan_yes
```

### 5.4 Days_binned_weeks
We bin days to weeks incase there is correlation between target and which week the target was contacted. 
```{r}
week_type <- function(day){
  week_num=0
  if(day < 7){
    week_num <-1
  }else if(day< 15){
    week_num <-2
  }else if(day<22){
    week_num <-3
  }else if(day<30){
    week_num<-4
  }else{week_num <-5}
  return(week_num)
}
merged_df$week <- as.factor(as.numeric(lapply(merged_df$day, FUN = week_type)))
dmy<-dummyVars("~.",data = merged_df)
merged_df<-data.table(predict(dmy, newdata = merged_df))
```

### 5.5 Season Quarters
In the EDA we have seen that trends differ to seasons. We therefore bin for seasons.
```{r}
merged_df$Q1 <- merged_df$month_jan+merged_df$month_feb+merged_df$month_mar
merged_df$Q2 <- merged_df$month_apr+merged_df$month_may+merged_df$month_jun
merged_df$Q3 <- merged_df$month_jul+merged_df$month_aug+merged_df$month_sep
merged_df$Q4 <- merged_df$month_oct+merged_df$month_nov+merged_df$month_dec

train_featured <- merged_df[1:nrow(train),]
train_featured$y <- y
test_featured <- merged_df[(nrow(train)+1):nrow(merged_df),]
```

## 6. Modeling

Here we define a number of models, to see which one will preform the best.

### 6.1 Logistic Regression
```{r, message=FALSE}
lm_over <- train_val(train_featured, "glm","over")
lm_under <- train_val(train_featured, "glm","under")
lm_S <- train_val(train_featured, "glm","SMOTE")
```

### 6.2  Random Forest
```{r, message=FALSE}
rf_over <- train_val(train_featured, "ranger","over")
rf_under <- train_val(train_featured, "ranger","under")
rf_S <- train_val(train_featured, "ranger","SMOTE")
```

### 6.3 XGBoosting Tree
```{r, message=FALSE}
xgb_over <- train_val(train_featured, "xgbTree","over")
xgb_under <- train_val(train_featured, "xgbTree","under")
xgb_S <- train_val(train_featured, "xgbTree","SMOTE")
```

### 6.4 Regression with regularization
```{r, message=FALSE}
glmnet_over <- train_val(train_featured, "glmnet","over")
glmnet_under <- train_val(train_featured, "glmnet","under")
glmnet_S <- train_val(train_featured, "glmnet","SMOTE")
```

### 6.5 Results
We print the results to compare the different models.

```{r}
results <- resamples(list(
    LMO = lm_over,
    LMU = lm_under,
    LMS = lm_S,
    RFO = rf_over,
    RFU = rf_under,
    RFS = rf_S,
    XGBO = xgb_over,
    XGBU = xgb_under,
    XGBS = xgb_S,
    GLO = glmnet_over,
    GLU = glmnet_under,
    GLS = glmnet_S)
)

summary(results)
```

### 6.6 Plot of Results
We plot the results to get a deeper understanding which is our best model.
```{r}
bwplot(results, layout = c(2, 1), scales = list(relation="free"))
```
Based on this, we realize that the best performing model is the Random Forest with SMOTE sampling.

## 7. Hyperparameter Tuning
Finally we perform a cross validated, randomized grid search on the chosen random forest in order to define the final model, optimizing for Recall.

```{r tuning}
grid<-expand.grid(
  mtry=c(16,32,63),
  splitrule=c('extratrees', 'gini'),
  min.node.size=c(1,3,5)
)

tc<-trainControl(
  method = "repeatedcv",
  number=5,
  repeats = 2,
  savePredictions = TRUE,
  summaryFunction = prSummary,
  classProbs=TRUE,
  search = "random"
)

ini<-now()

model_train<-SMOTE(y ~ ., data  = train_featured) 

grid_rf <- train(
  y ~ .,
  data = model_train,
  method = "ranger",
  num.trees=500,
  tuneGrid = grid,
  trControl = tc,
  metric = "Recall",
  tuneLength = 5,
  verbose = TRUE,
  importance = "impurity",
  preProcess=pp
)

print(now()-ini)

grid_rf
```

```{r}
grid_rf$bestTune
```

```{r}
grid_rf$finalModel
```

```{r}
plot(grid_rf)
```

```{r}
plot(varImp(grid_rf), top = 20)
```

## 8. Predictions
We predict on the test set, add the predictions to it and create our predictions file.

```{r predictions}
predicted <- predict(grid_rf, newdata = test_featured)
df_pred<-cbind(test, predicted)
head(df_pred)
```

```{r}
fwrite(df_pred[,c("predicted")],"predictions.csv")
```

## 9. Conclusions

We conclude that after extensive feature exploration, engineering and modelling that the best preforming model is a Random Forrest with SMOTE sampling and the following parameters. (Explain Parameters),

The accuracy... 

Our final feature set...