---
title: "GroupE_Classification"
date: "5/29/2019"
output:
  html_document:
    toc: true
    toc_depth: 3
author: "Group E"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
start_time <- Sys.time()
print(paste0('---START--- Starting at ',start_time))
packages_list <- c(
  'caret',
  'data.table',
  'ggplot2',
  'lubridate',
  'MLmetrics')
for (i in packages_list){
  if(!i%in%installed.packages()){
    install.packages(i, dependencies = TRUE)
    library(i, character.only = TRUE)
    print(paste0(i, ' has been installed'))
  } else {
    print(paste0(i, ' is already installed'))
    library(i, character.only = TRUE)
  }
}
print(paste0('[', round(difftime(Sys.time(),start_time, units = 'secs'),1), 's]: ',
             'All necessary packages installed and loaded'))
```

# Classifying Term Deposits

## 1. Introduction
The dataset provided gathers information related to telemarketing campaigns applied by a banking institution. It is important to mention that a client was contacted a few times in order to see if the product (term deposit) would be or not subscribed.

The goal of the project is to predict by using a classification model if a client will subscribe for a term deposit, having as a target variable a binary parameter with possible outcomes 'yes' or 'no'.

## 2. Data Loading and Preprocessing

Here we load the necessary train and test data.

```{r Load Data, include=FALSE}
# Loading the Data
train = fread("BankCamp_train.csv", stringsAsFactors = T)
test = fread("BankCamp_test.csv", stringsAsFactors = T)
```

These are the first few rows of the training data.

```{r head}
head(train)
```

This is the structure of the data.

```{r str}
str(train)
```

This is the summary of the data.

```{r summary}
summary(train)
```

Now we check if there are missing values in any column:

```{r missing}
sapply(train, function(x) sum(is.na(x)))
```

We also check if there are any duplicate values:

```{r duplicated}
any(duplicated(train))
```

Finally we set the types for numerical variables:

```{r numerical}
train[ , which(sapply(train, is.integer)):=lapply(.SD,as.numeric), .SDcols = sapply(train, is.integer)]
test[ , which(sapply(test, is.integer)):=lapply(.SD,as.numeric), .SDcols = sapply(test, is.integer)]
str(train)
```

## 3. Data Exploration

## 4. Baseline

We dummy encode the factor variables to be able to run different models on the data.

```{r dummy}
dummy<-dummyVars(formula= ~., data = train[, -"y"], fullRank=T, sep = "_")
final_train<-data.table(predict(dummy, newdata = train[, -"y"]))
final_train$y<-train$y
final_test<-data.table(predict(dummy, newdata = test))
head(final_train)
```

Now we will run a simple logistic regression as a baseline, this will serve as a way of knowing if our feature engineering steps improve performance.

```{r baseline}
tc<-trainControl(
  method = "cv",
  number=5,
  savePredictions = TRUE,
  classProbs=TRUE,
  summaryFunction = prSummary)
ini<-now()
lm <- train(y~ ., data = final_train, method = "glm", metric="AUC", trControl=tc)
print(now()-ini)
lm
```
So our Sensitivity or Recall is very high, meaning that we correctly classify 97% of the yes cases, our precision on the other hand is 92%.

Now we run a random forest as an alternative baseline.

```{r}
ini<-now()
rf <- train(y~ ., data = final_train, method = "ranger", metric="AUC", trControl=tc)
print(now()-ini)
rf
```

```{r}
rf$results
```

## 5. Feature Engineering

##### Feature Engineering
```{r feature engineering}
y <- final_train$y
final_train$y <- NULL
merged_df <- rbind(final_train, final_test)

# *Days to end of month* assuming all the months have 30 days
merged_df$days_to_end_of_month <- 30 - merged_df$day

# Balance General Status -> 1 if positive, 0 if negative or 0

positive_balance <- function(number){
  is_positive = 0
  if(number>0){is_positive <- 1}
  return(is_positive)
}
merged_df$balance_general_status <- as.numeric(lapply(merged_df$balance,  FUN = positive_balance))


# Quantity of loans 0, 1 or 2 (housing and personal)
merged_df$quantity_loans <- merged_df$housing_yes+merged_df$loan_yes

#Days_binned_weeks

week_type <- function(day){
  week_num=0
  if(day < 7){
    week_num <-1
  }else if(day< 15){
    week_num <-2
  }else if(day<22){
    week_num <-3
  }else if(day<30){
    week_num<-4
  }else{week_num <-5}
  return(week_num)
}
merged_df$week <- as.factor(as.numeric(lapply(merged_df$day, FUN = week_type)))
dmy<-dummyVars("~.",data = merged_df)
merged_df<-data.table(predict(dmy, newdata = merged_df))

#Season Quarters
merged_df$Q1 <- merged_df$month_jan+merged_df$month_feb+merged_df$month_mar
merged_df$Q2 <- merged_df$month_may+merged_df$month_jun
merged_df$Q3 <- merged_df$month_jul+merged_df$month_aug+merged_df$month_sep
merged_df$Q4 <- merged_df$month_oct+merged_df$month_nov+merged_df$month_dec

train_featured <- merged_df[1:nrow(train),]
test_featured <- merged_df[(nrow(train)+1):nrow(merged_df),]

```



## 6. Modeling
```{r models}

```


## 7. Hyperparameter Tuning
```{r tuning}

```


## 8. Results Evaluation
```{r results evaluation}

```


## 9. Extras
```{r extras}

```

