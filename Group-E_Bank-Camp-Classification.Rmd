---
title: "GroupE_Classification"
date: "5/29/2019"
output:
  html_document:
    toc: true
    toc_depth: 3
author: "Group E"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
start_time <- Sys.time()
print(paste0('---START--- Starting at ',start_time))
packages_list <- c(
  'caret',
  'corrplot',
  'data.table',
  'DMwR',
  'ggplot2',
  'lubridate',
  'MLmetrics')
for (i in packages_list){
  if(!i%in%installed.packages()){
    install.packages(i, dependencies = TRUE)
    library(i, character.only = TRUE)
    print(paste0(i, ' has been installed'))
  } else {
    print(paste0(i, ' is already installed'))
    library(i, character.only = TRUE)
  }
}
print(paste0('[', round(difftime(Sys.time(),start_time, units = 'secs'),1), 's]: ',
             'All necessary packages installed and loaded'))
```

# Classifying Term Deposits

## 1. Introduction
The dataset provided gathers information related to telemarketing campaigns applied by a banking institution. It is important to mention that a client was contacted a few times in order to see if the product (term deposit) would be or not subscribed.

The goal of the project is to predict by using a classification model if a client will subscribe for a term deposit, having as a target variable a binary parameter with possible outcomes 'yes' or 'no'.

## 2. Data Loading and Preprocessing

Here we load the necessary train and test data.

```{r load}
train = fread("BankCamp_train.csv", stringsAsFactors = T)
test = fread("BankCamp_test.csv", stringsAsFactors = T)
```

Here we switch the order of the factors, to get metrics related to the yes target.

```{r change_factors}
train$y <- factor(train$y, levels = c("yes", "no"))
test$y <- factor(test$y, levels = c("yes", "no"))
```

These are the first few rows of the training data.

```{r head}
head(train)
```

This is the structure of the data.

```{r str}
str(train)
```

This is the summary of the data.

```{r summary}
summary(train)
```

Now we check if there are missing values in any column:

```{r missing}
sapply(train, function(x) sum(is.na(x)))
```

We also check if there are any duplicate values:

```{r duplicated}
any(duplicated(train))
```

Finally we set the types for numerical variables:

```{r numerical}
train[ , which(sapply(train, is.integer)):=lapply(.SD,as.numeric), .SDcols = sapply(train, is.integer)]
test[ , which(sapply(test, is.integer)):=lapply(.SD,as.numeric), .SDcols = sapply(test, is.integer)]
str(train)
```

## 3. Data Exploration

### Correlation Plot
```{r}
numVars<-c('age','balance','day', 'duration', 'campaign', 'previous')

trainCorrplot<- train[,..numVars]
corresult = cor(trainCorrplot)
corrplot(corresult,  type="upper")
```

### Distributions of numerical variables
```{r}
for(i in numVars){
  counts <- table(train[,..i])
  barplot(counts, main = i, col = "dodgerblue4")
}
```

### Distributions of categorical variables
```{r}
catVars <- colnames(train[,-..numVars])

for(i in catVars){
  counts <- table(train[,..i])
  barplot(counts, main = i,  col = "dodgerblue4")
}
```

### Job
##### Job univariate bar chart (count)
```{r}
sort(summary(train$job), dec=T)/nrow(train)

p1<-ggplot(train, aes(x=job))+geom_bar(stat='count',fill="dodgerblue4", colour="dodgerblue4")+
  theme(axis.text.x = element_text(angle=0))+ labs(title = "Distribution by Kind of Job")+
  xlab("Job")+ ylab("Count")
train[, job:=factor(job, levels=names(sort(summary(train$job), dec=T)))]
levels(train$job)
p1
```

### Marital
#### Marital univariate bar chart (count)
```{r}
sort(summary(train$marital), dec=T)/nrow(train)

p2<-ggplot(train, aes(x=marital))+geom_bar(stat='count',fill="dodgerblue4", colour="dodgerblue4")+
  theme(axis.text.x = element_text(angle=0))+ labs(title = "Distribution by Marital Status")+
  xlab("Marital Status")+ ylab("Count")
train[, marital:=factor(marital, levels=names(sort(summary(train$marital), dec=T)))]
levels(train$marital)
p2
```

### Education
##### Education univariate bar chart (count)
```{r}
sort(summary(train$education), dec=T)/nrow(train)

p3<-ggplot(train, aes(x=education))+geom_bar(stat='count',fill="dodgerblue4", colour="dodgerblue4")+
  theme(axis.text.x = element_text(angle=0))+labs(title = "Distribution by Education Level")+
  xlab("Education Level")+ ylab("Count")
train[, education:=factor(education, levels=names(sort(summary(train$education), dec=T)))]
levels(train$education)
p3
```

### Month
#### Month univariate bar chart (count)
```{r}
sort(summary(train$month), dec=T)/nrow(train)
train$month <- factor(train$month, levels = c( "jan", "feb", "mar", "apr","may", "jun", "jul", "aug", "sep", "oct", "nov", "dec"))
p4<-ggplot(train, aes(x=month))+geom_bar(stat='count',fill="dodgerblue4", colour="dodgerblue4")+
  theme(axis.text.x = element_text(angle=90))+labs(title = "Distribution by Month")+
  xlab("Month")+ ylab("Count")
levels(train$month)
p4
```
### Age
#### Age univariate bar chart (count)
```{r}
sort(summary(train$age), dec=T)/nrow(train)
p5<-ggplot(train, aes(x=age))+geom_histogram(fill="dodgerblue4", colour="dodgerblue4", bins=30)+
  theme(axis.text.x = element_text(angle=0, colour = "dodgerblue4"))+
  labs(title = "Distribution by Age")+xlab("Age")+ ylab("Count")
levels(train$age)
p5
```

### Bivariate Analysis
#### Marital 
```{r}
#Marital + Loan bar chart (count)
p6<-ggplot(train, 
           aes(x = marital, 
               fill = loan)) + 
  geom_bar(position = "dodge")+ scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
  labs(title = "Loan Acquisition by Marital Status")+xlab("Marital Status")+ ylab("Count")
p6
```

#### Marital + Default bar chart (count)
```{r}
p7<-ggplot(train, 
             aes(x = marital, 
                 fill = default)) + 
    geom_bar(position = "dodge")+ scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
  labs(title = "Default by Marital Status")+xlab("Marital Status")+ ylab("Count")
p7
```

#### Marital + y bar chart (percent)
```{r}
mytable <- table(train$marital, train$y)
tab <- as.data.frame(prop.table(mytable, 2))
colnames(tab) <-  c("marital", "y", "perc")

p8<-ggplot(data = tab, aes(x = marital, y = perc, fill = y)) + 
  geom_bar(stat = 'identity', position = 'dodge', alpha = 1) + scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
  labs(title = "Term Deposit Subscription by Marital Status")+xlab("Marital Status")+ ylab("Percent")
p8
```

### Education
#### Education + Loan bar chart (count)
```{r}
p9<-ggplot(train, 
           aes(x = education, 
               fill = loan)) + 
  geom_bar(position = "dodge")+ scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
  labs(title = "Loan Acquisition by Education Level")+xlab("Education Level")+ ylab("Count")
p9
```

### Education + Default bar chart (count)
```{r}
p10<-ggplot(train, 
           aes(x = education, 
               fill = default)) + 
  geom_bar(position = "dodge")+ scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
  labs(title = "Default by Education Level")+xlab("Education Level")+ ylab("Count")
p10
```

#### Education + y bar chart (percent)
```{r}
mytable <- table(train$education, train$y)
tab <- as.data.frame(prop.table(mytable, 2))
colnames(tab) <-  c("education", "y", "perc")

p11<- ggplot(data = tab, aes(x = education, y = perc, fill = y)) + 
  geom_bar(stat = 'identity', position = 'dodge', alpha = 1) + scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
labs(title = "Term Deposit Subscription by Education Level")+xlab("Education Level")+ ylab("Percent")
p11
```

### Job
#### Job + Loan bar chart (count)
```{r}
p12<-ggplot(train, 
           aes(x = job, 
               fill = loan)) + 
  geom_bar(position = "dodge")+ scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+theme(axis.text.x = element_text(angle=90))+
  labs(title = "Job by Loan Status")+xlab("Job")+ ylab("Count")
p12
```

#### Job + Default bar chart (count)
```{r}
p13<-ggplot(train, 
            aes(x = job, 
                fill = default)) + 
  geom_bar(position = "dodge")+ scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+theme(axis.text.x = element_text(angle=90))+
  labs(title = "Default Status by Job")+xlab("Job")+ ylab("Count")
p13
```

#### Job + y bar chart (percent)
```{r}
mytable <- table(train$job, train$y)
tab <- as.data.frame(prop.table(mytable, 2))
colnames(tab) <-  c("job", "y", "perc")

p14<-ggplot(data = tab, aes(x = job, y = perc, fill = y)) + 
  geom_bar(stat = 'identity', position = 'dodge', alpha = 1) + scale_fill_manual(values=c("dodgerblue4","dodgerblue3"))+
  theme(axis.text.x = element_text(angle = 90, hjust = 1))+
  labs(title = "Term Deposit Subscription by Job")+xlab("Job")+ ylab("Percent")
p14
```

### Balance
#### Balance + education box plot
```{r}
p15<-ggplot(train, 
       aes(x = education, 
           y = balance)) + geom_line(size = 1.5, 
                                     color = "lightgrey") +
  geom_boxplot(fill="dodgerblue3", color="dodgerblue4") +
  labs(title = "Balance by Education Level")+xlab("Education")+ ylab("Balance")
p15
```

### Balance + education scatter plot
```{r}
p16<-ggplot(train, 
            aes(y = balance, 
                x = education)) +  
  geom_jitter(color = "dodgerblue4") + 
  labs(title = "Balance Distribution by Education Level")+theme(axis.text.x = element_text(angle=90))+
  xlab("Education")+ ylab("Balance")
p16
```

#### Balance + job box plot
```{r}
p17<-ggplot(train, 
            aes(x = job, 
                y = balance)) + geom_line(size = 1.5, 
                                          color = "lightgrey") +
  geom_boxplot(fill="dodgerblue3", color="dodgerblue4") +
  labs(title = "Balance by Kind of Job")+theme(axis.text.x = element_text(angle=90))+
  xlab("Job")+ ylab("Balance")
p17
```

#### Balance + job scatter plot
```{r}
p18<-ggplot(train, 
       aes(y = balance, 
           x = job)) +  
  geom_jitter(color = "dodgerblue4") + 
  labs(title = "Balance Distribution by Kind of Job")+theme(axis.text.x = element_text(angle=90))+
  xlab("Job")+ ylab("Balance")
p18
```

#### Duration + y
```{r}
p19<-ggplot(train, aes(x=as.factor(y), y=duration)) +
  geom_boxplot(fill="dodgerblue3", color="dodgerblue4")+
  theme_classic()+labs(title = "Call Duration by Term Deposit Subscription")+xlab("Term deposit")+
  ylab("Call Duration (sec.)")
p19
```

#### Pdays + y
```{r}
p20<-ggplot(train, aes(x=as.factor(y), y=pdays)) +
  geom_boxplot(fill="dodgerblue3", color="dodgerblue4")+
  theme_classic()+labs(title = "Days from last contact by Term Deposit Subscription")+xlab("Term deposit")+
  ylab("Days from last contact")
p20
```

#### Previous + y
```{r}
p21<-ggplot(train, aes(x=as.factor(y), y=previous)) +
  geom_boxplot(fill="dodgerblue3", color="dodgerblue4")+
  theme_classic()+labs(title = "Contacts before this Campaign by Term Deposit Subscription")+xlab("Term deposit")+
  ylab("Contacts before this campaign")
p21
```

#### Campaign + y
```{r}
p22<-ggplot(train, aes(x=as.factor(y), y=campaign)) +
  geom_boxplot(fill="dodgerblue3", color="dodgerblue4")+
  theme_classic()+labs(title = "Contacts during this Campaign by Term Deposit Subscription")+xlab("Term deposit")+
  ylab("Contacts during this campaign")
p22
```

## 4. Baseline

We dummy encode the factor variables to be able to run different models on the data.

```{r dummy}
dummy<-dummyVars(formula= ~., data = train[, -"y"], sep = "_")
final_train<-data.table(predict(dummy, newdata = train[, -"y"]))
final_train$y<-train$y
final_test<-data.table(predict(dummy, newdata = test))
head(final_train)
```

Now we define our training function, it will perform a 5 fold cross validation on 80% of the training data and then a final validation on the remaining 20% of the data that acts as a holdout.

```{r}
train_val<- function(train_dt, model, sampling){
  tc<-trainControl(
    method = "cv",
    number=5,
    savePredictions = TRUE,
    classProbs=TRUE,
    summaryFunction = prSummary)

  trainIndex <- createDataPartition(train_dt$y, p = .8, list = FALSE)
  model_train <- train_dt[ trainIndex,]
  holdout  <- train_dt[-trainIndex,]
  
  if(!missing(sampling)){
    if(sampling == 'over'){
      model_train<-upSample(x = model_train[, -"y"],y = model_train$y, yname="y")
    }
    else if(sampling == 'under'){
      model_train<-downSample(x = model_train[, -"y"],y = model_train$y, yname="y")
    }
    else {
      model_train<-SMOTE(y ~ ., data  = model_train) 
    }
  }
  
  ini<-now()
  model<- train(y~ ., data = model_train, method = model, metric="AUC", trControl=tc)
  message("Cross Validation Scores having Yes as the positive class")
  message(model$results)
  message("Train + Predict time:")
  message(now()-ini)
  
  predicted = predict(model, newdata = holdout)
  
  message("Holdout Scores")
  message(confusionMatrix(table(predicted, holdout$y), positive="yes", mode="everything"))
  
  return(model)
}
```

Now we will run a simple logistic regression as a baseline, this will serve as a way of knowing if our feature engineering steps improve performance.

```{r baseline}
lm <- train_val(final_train, "glm")
```

So our Sensitivity or Recall is very low based on the "yes" class, meaning that we correctly classify a really small set of the "yes" cases.

Now we run a random forest as an alternative baseline.

```{r}
rf <- train_val(final_train, "ranger")
```

## 5. Feature Engineering
```{r feature engineering}
y <- final_train$y
final_train$y <- NULL
merged_df <- rbind(final_train, final_test)

# *Days to end of month* assuming all the months have 30 days
merged_df$days_to_end_of_month <- 30 - merged_df$day

# Balance General Status -> 1 if positive, 0 if negative or 0

positive_balance <- function(number){
  is_positive = 0
  if(number>0){is_positive <- 1}
  return(is_positive)
}
merged_df$balance_general_status <- as.numeric(lapply(merged_df$balance,  FUN = positive_balance))


# Quantity of loans 0, 1 or 2 (housing and personal)
merged_df$quantity_loans <- merged_df$housing_yes+merged_df$loan_yes

#Days_binned_weeks

week_type <- function(day){
  week_num=0
  if(day < 7){
    week_num <-1
  }else if(day< 15){
    week_num <-2
  }else if(day<22){
    week_num <-3
  }else if(day<30){
    week_num<-4
  }else{week_num <-5}
  return(week_num)
}
merged_df$week <- as.factor(as.numeric(lapply(merged_df$day, FUN = week_type)))
dmy<-dummyVars("~.",data = merged_df)
merged_df<-data.table(predict(dmy, newdata = merged_df))

#Season Quarters
merged_df$Q1 <- merged_df$month_jan+merged_df$month_feb+merged_df$month_mar
merged_df$Q2 <- merged_df$month_apr+merged_df$month_may+merged_df$month_jun
merged_df$Q3 <- merged_df$month_jul+merged_df$month_aug+merged_df$month_sep
merged_df$Q4 <- merged_df$month_oct+merged_df$month_nov+merged_df$month_dec

train_featured <- merged_df[1:nrow(train),]
train_featured$y <- y
test_featured <- merged_df[(nrow(train)+1):nrow(merged_df),]

```



## 6. Modeling

### Logistic Regression
```{r, message=FALSE, warning=FALSE}
lm_over <- train_val(train_featured, "glm","over")
lm_under <- train_val(train_featured, "glm","under")
lm_S <- train_val(train_featured, "glm","SMOTE")
```

### Random Forest
```{r, message=FALSE, warning=FALSE}
rf_over <- train_val(train_featured, "ranger","over")
rf_under <- train_val(train_featured, "ranger","under")
rf_S <- train_val(train_featured, "ranger","SMOTE")
```

### XGBoosting Tree
```{r, message=FALSE, warning=FALSE}
xgb_over <- train_val(train_featured, "xgbTree","over")
xgb_under <- train_val(train_featured, "xgbTree","under")
xgb_S <- train_val(train_featured, "xgbTree","SMOTE")
```

### Regression with regularization
```{r, message=FALSE, warning=FALSE}
glmnet_over <- train_val(train_featured, "glmnet","over")
glmnet_under <- train_val(train_featured, "glmnet","under")
glmnet_S <- train_val(train_featured, "glmnet","SMOTE")
```

### Results
```{r}
results <- resamples(list(
    LMO = lm_over,
    LMU = lm_under,
    LMS = lm_S,
    RFO = rf_over,
    RFU = rf_under,
    RFS = rf_S,
    XGBO = xgb_over,
    XGBU = xgb_under,
    XGBS = xgb_S,
    GLO = glmnet_over,
    GLU = glmnet_under,
    GLS = glmnet_S),
)

summary(results)
```

### Plot of Results
```{r}
bwplot(results, layout = c(4, 1), scales = list(relation="free"))
```

## 7. Hyperparameter Tuning
```{r tuning}

```


## 8. Results Evaluation
```{r results evaluation}

```


## 9. Extras
```{r extras}

```

